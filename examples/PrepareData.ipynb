{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aeon.datasets._data_loaders import load_classification\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"GunPoint\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Check for Numpy array present \n",
    "\n",
    "# 1. Get Dataset from Aeon Website and load it\n",
    "# 2. update the labels\n",
    "# 2.1 create meta data dict\n",
    "# 3. save the dataset as a numpy array and the dict as a json file\n",
    "# 4. delete the old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\n",
    "np_path = f\".cache/data/{dataset_name}/{dataset_name}.npz\"\n",
    "json_path = f\".cache/data/{dataset_name}/{dataset_name}.json\"\n",
    "if os.path.exists(np_path) and os.path.exists(json_path):\n",
    "    print(\"TaDaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemname': 'gunpoint', 'timestamps': False, 'missing': False, 'univariate': True, 'equallength': True, 'classlabel': True, 'targetlabel': False, 'class_values': ['1', '2']}\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "extract_path = f\".cache/temp\"\n",
    "X, Y, meta = load_classification(name=dataset_name, split=None, extract_path=extract_path, return_metadata=True)\n",
    "X_train, Y_train = load_classification(name=dataset_name, split=\"train\", extract_path=extract_path, return_metadata=False)\n",
    "X_test, Y_test = load_classification(name=dataset_name, split=\"test\", extract_path=extract_path, return_metadata=False)\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 1\n",
      " 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "def update_labels(y):\n",
    "    labels = []\n",
    "    for label in y:\n",
    "        l = int(label)\n",
    "        if l not in labels:\n",
    "            labels.append(l)\n",
    "    labels = np.sort(labels)\n",
    "    for idx, label in enumerate(labels):\n",
    "        y[y == str(label)] = idx\n",
    "\n",
    "    labels = [i for i in range(len(labels))]\n",
    "    return y.astype(np.int32), labels\n",
    "\n",
    "Y, labels = update_labels(Y)\n",
    "print(Y)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [0, 1], 'num_classes': 2, 'num_features': 1, 'num_samples': 200, 'num_train_samples': 50, 'num_test_samples': 150, 'length': 150}\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "meta_data = {\n",
    "    \"labels\": labels,\n",
    "    \"num_classes\": len(labels),\n",
    "    \"num_features\": X.shape[1],\n",
    "    \"num_samples\": X.shape[0], \n",
    "    \"num_train_samples\": X_train.shape[0],\n",
    "    \"num_test_samples\": X_test.shape[0],\n",
    "    \"length\": X.shape[2]}\n",
    "print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "os.makedirs(f\".cache/data/{dataset_name}\", exist_ok=True)\n",
    "# Does X and Y have to be saved?\n",
    "np.savez_compressed(np_path , X=X, Y=Y, X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test)\n",
    "json.dump(meta_data, open(json_path, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"rm -rf {extract_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
